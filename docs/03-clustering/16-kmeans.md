# K-Means Clustering

## 1. Â¿QuÃ© es K-Means?

### Concepto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K-MEANS = Particionar datos en K clusters                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  OBJETIVO: Minimizar la distancia de cada punto a su           â”‚
â”‚            centroide (centro del cluster)                      â”‚
â”‚                                                                â”‚
â”‚  ENTRADA:                                                      â”‚
â”‚    â€¢ Dataset X con n puntos                                    â”‚
â”‚    â€¢ NÃºmero de clusters K (tÃº lo decides)                      â”‚
â”‚                                                                â”‚
â”‚  SALIDA:                                                       â”‚
â”‚    â€¢ K centroides (centros de los clusters)                    â”‚
â”‚    â€¢ AsignaciÃ³n de cada punto a un cluster                     â”‚
â”‚                                                                â”‚
â”‚       â—  â—                  â˜… = Centroide                      â”‚
â”‚     â—   â—  â—                â— = Puntos del cluster             â”‚
â”‚    â—  â˜…    â—                                                   â”‚
â”‚      â—   â—                  Cada punto pertenece al cluster    â”‚
â”‚    â—   â—                    cuyo centroide estÃ¡ MÃS CERCA      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FunciÃ³n Objetivo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FUNCIÃ“N DE COSTE (INERTIA)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  J = Î£áµ¢ Î£â‚“âˆˆCáµ¢ ||x - Î¼áµ¢||Â²                                     â”‚
â”‚                                                                â”‚
â”‚  Donde:                                                        â”‚
â”‚    Cáµ¢ = cluster i                                              â”‚
â”‚    Î¼áµ¢ = centroide del cluster i                                â”‚
â”‚    x = cada punto del cluster                                  â”‚
â”‚                                                                â”‚
â”‚  OBJETIVO: Minimizar J (suma de distancias al cuadrado)        â”‚
â”‚                                                                â”‚
â”‚  Cluster compacto:              Cluster disperso:              â”‚
â”‚       â—â—â—                          â—        â—                  â”‚
â”‚      â—â˜…â—â—                              â˜…                       â”‚
â”‚       â—â—                           â—         â—                 â”‚
â”‚    J bajo (bueno)                  J alto (malo)               â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. El Algoritmo K-Means

### Pasos del Algoritmo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALGORITMO K-MEANS                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  PASO 1: INICIALIZACIÃ“N                                        â”‚
â”‚    Elegir K puntos aleatorios como centroides iniciales        â”‚
â”‚                                                                â”‚
â”‚  PASO 2: ASIGNACIÃ“N                                            â”‚
â”‚    Asignar cada punto al centroide mÃ¡s cercano                 â”‚
â”‚                                                                â”‚
â”‚  PASO 3: ACTUALIZACIÃ“N                                         â”‚
â”‚    Recalcular centroides como la media de sus puntos           â”‚
â”‚                                                                â”‚
â”‚  PASO 4: REPETIR                                               â”‚
â”‚    Repetir pasos 2-3 hasta que los centroides no cambien       â”‚
â”‚    (o cambien menos que un umbral)                             â”‚
â”‚                                                                â”‚
â”‚  CONVERGENCIA:                                                 â”‚
â”‚    El algoritmo SIEMPRE converge                               â”‚
â”‚    Pero puede quedar en un mÃ­nimo LOCAL                        â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### VisualizaciÃ³n Paso a Paso

```
ITERACIÃ“N 0 (InicializaciÃ³n):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â—  â—  â—‹  â—‹
  â—   â—    â—‹   â—‹
   â—  â—  â—‹   â—‹  â—‹
    â—   â—‹  â—‹

    â˜…â‚           â˜…â‚‚      â† Centroides aleatorios

ITERACIÃ“N 1 (AsignaciÃ³n + ActualizaciÃ³n):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â—  â—  â”‚  â—‹  â—‹
  â—   â—   â”‚   â—‹   â—‹      â† Puntos asignados al centroide mÃ¡s cercano
   â—  â—   â”‚ â—‹   â—‹  â—‹
    â—     â”‚  â—‹  â—‹
          â”‚
     â˜…â‚   â”‚    â˜…â‚‚        â† Centroides recalculados (media)

ITERACIÃ“N 2:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â—  â—    â”‚  â—‹  â—‹
  â—   â—     â”‚   â—‹   â—‹
   â—  â—     â”‚â—‹   â—‹  â—‹    â† Frontera se ajusta
    â—       â”‚ â—‹  â—‹
            â”‚
      â˜…â‚    â”‚   â˜…â‚‚       â† Centroides se mueven

CONVERGENCIA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â—  â—    â”‚  â—‹  â—‹
  â—   â—     â”‚   â—‹   â—‹
   â— â˜…â‚â—    â”‚  â˜…â‚‚ â—‹  â—‹   â† Centroides ya no cambian
    â—       â”‚ â—‹  â—‹
```

### PseudocÃ³digo

```python
def kmeans(X, K, max_iter=100):
    # 1. Inicializar centroides aleatoriamente
    centroides = random_sample(X, K)

    for _ in range(max_iter):
        # 2. Asignar cada punto al centroide mÃ¡s cercano
        labels = []
        for x in X:
            distancias = [distancia(x, c) for c in centroides]
            labels.append(argmin(distancias))

        # 3. Recalcular centroides
        nuevos_centroides = []
        for k in range(K):
            puntos_cluster = X[labels == k]
            nuevos_centroides.append(mean(puntos_cluster))

        # 4. Verificar convergencia
        if centroides == nuevos_centroides:
            break
        centroides = nuevos_centroides

    return centroides, labels
```

## 3. InicializaciÃ³n: K-Means++

### El Problema de la InicializaciÃ³n Aleatoria

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROBLEMA: InicializaciÃ³n afecta el resultado                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  MALA inicializaciÃ³n:           BUENA inicializaciÃ³n:          â”‚
â”‚                                                                â”‚
â”‚    â—â—â—        â—‹â—‹â—‹                 â—â—â—        â—‹â—‹â—‹               â”‚
â”‚   â—â—â—â—       â—‹â—‹â—‹â—‹                â—â—â—â—       â—‹â—‹â—‹â—‹               â”‚
â”‚    â—â—â—        â—‹â—‹â—‹                 â—â—â—        â—‹â—‹â—‹               â”‚
â”‚                                                                â”‚
â”‚   â˜…â‚ â˜…â‚‚                            â˜…â‚          â˜…â‚‚              â”‚
â”‚   (ambos en el mismo lado)        (uno en cada grupo)          â”‚
â”‚                                                                â”‚
â”‚   Resultado: Un cluster vacÃ­o     Resultado: Correcto          â”‚
â”‚   o muy desbalanceado                                          â”‚
â”‚                                                                â”‚
â”‚  SOLUCIÃ“N: K-Means++ (inicializaciÃ³n inteligente)              â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algoritmo K-Means++

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K-MEANS++ INICIALIZACIÃ“N                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. Elegir primer centroide uniformemente al azar              â”‚
â”‚                                                                â”‚
â”‚  2. Para cada punto x, calcular D(x) = distancia al            â”‚
â”‚     centroide mÃ¡s cercano ya elegido                           â”‚
â”‚                                                                â”‚
â”‚  3. Elegir siguiente centroide con probabilidad                â”‚
â”‚     proporcional a D(x)Â²                                       â”‚
â”‚     (puntos lejanos tienen mÃ¡s probabilidad)                   â”‚
â”‚                                                                â”‚
â”‚  4. Repetir 2-3 hasta tener K centroides                       â”‚
â”‚                                                                â”‚
â”‚  RESULTADO:                                                    â”‚
â”‚    Centroides tienden a estar bien distribuidos                â”‚
â”‚    Mucho mejor que aleatorio puro                              â”‚
â”‚                                                                â”‚
â”‚  En sklearn: init='k-means++' (default)                        â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃºltiples Inicializaciones

```python
from sklearn.cluster import KMeans

# n_init = nÃºmero de veces que se ejecuta con diferentes inicializaciones
# Se queda con la mejor (menor inertia)
kmeans = KMeans(
    n_clusters=3,
    init='k-means++',   # InicializaciÃ³n inteligente
    n_init=10,          # Ejecutar 10 veces, quedarse con la mejor
    random_state=42
)
```

## 4. ImplementaciÃ³n en Python

### CÃ³digo BÃ¡sico

```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

# Generar datos de ejemplo
np.random.seed(42)
X = np.vstack([
    np.random.randn(100, 2) + [0, 0],
    np.random.randn(100, 2) + [5, 5],
    np.random.randn(100, 2) + [10, 0]
])

# IMPORTANTE: Escalar datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Crear y entrenar K-Means
kmeans = KMeans(
    n_clusters=3,
    init='k-means++',
    n_init=10,
    max_iter=300,
    random_state=42
)

# Fit y predecir
labels = kmeans.fit_predict(X_scaled)

# Resultados
print(f"Centroides:\n{kmeans.cluster_centers_}")
print(f"Inertia: {kmeans.inertia_:.2f}")
print(f"NÃºmero de iteraciones: {kmeans.n_iter_}")
print(f"Labels: {labels[:10]}...")
```

### Encontrar K Ã“ptimo

```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# MÃ©todo del codo + Silhouette
K_range = range(2, 11)
inertias = []
silhouettes = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouettes.append(silhouette_score(X_scaled, labels))

# Visualizar
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

ax1.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)
ax1.set_xlabel('K')
ax1.set_ylabel('Inertia')
ax1.set_title('MÃ©todo del Codo')
ax1.grid(True, alpha=0.3)

ax2.plot(K_range, silhouettes, 'ro-', linewidth=2, markersize=8)
ax2.set_xlabel('K')
ax2.set_ylabel('Silhouette Score')
ax2.set_title('AnÃ¡lisis Silhouette')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Mejor K
best_k = K_range[np.argmax(silhouettes)]
print(f"Mejor K segÃºn Silhouette: {best_k}")
```

### VisualizaciÃ³n de Clusters

```python
import matplotlib.pyplot as plt

def plot_kmeans(X, labels, centroids, title="K-Means Clustering"):
    plt.figure(figsize=(10, 8))

    # Plot puntos coloreados por cluster
    scatter = plt.scatter(X[:, 0], X[:, 1], c=labels,
                         cmap='viridis', alpha=0.6, s=50)

    # Plot centroides
    plt.scatter(centroids[:, 0], centroids[:, 1],
               c='red', marker='X', s=200, edgecolors='black',
               linewidth=2, label='Centroides')

    plt.colorbar(scatter, label='Cluster')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

# Usar
plot_kmeans(X_scaled, labels, kmeans.cluster_centers_)
```

## 5. HiperparÃ¡metros

### Tabla de HiperparÃ¡metros

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ParÃ¡metro     â”‚   Default   â”‚   DescripciÃ³n                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ n_clusters      â”‚      8      â”‚ NÃºmero de clusters (K)         â”‚
â”‚                 â”‚             â”‚ DEBES elegirlo tÃº              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ init            â”‚ 'k-means++' â”‚ MÃ©todo de inicializaciÃ³n       â”‚
â”‚                 â”‚             â”‚ 'k-means++', 'random', o array â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ n_init          â”‚     10      â”‚ NÃºmero de inicializaciones     â”‚
â”‚                 â”‚             â”‚ (se queda con la mejor)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_iter        â”‚    300      â”‚ MÃ¡ximo de iteraciones          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tol             â”‚   1e-4      â”‚ Tolerancia para convergencia   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm       â”‚  'lloyd'    â”‚ Algoritmo: 'lloyd' o 'elkan'   â”‚
â”‚                 â”‚             â”‚ elkan mÃ¡s rÃ¡pido para K bajo   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ random_state    â”‚    None     â”‚ Semilla para reproducibilidad  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 6. Mini-Batch K-Means

### Para Datasets Grandes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MINI-BATCH K-MEANS                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  K-Means estÃ¡ndar usa TODOS los datos en cada iteraciÃ³n        â”‚
â”‚  â†’ Lento para datasets muy grandes                             â”‚
â”‚                                                                â”‚
â”‚  Mini-Batch K-Means usa solo un SUBSET (batch) por iteraciÃ³n   â”‚
â”‚  â†’ Mucho mÃ¡s rÃ¡pido                                            â”‚
â”‚  â†’ Resultado ligeramente peor pero aceptable                   â”‚
â”‚                                                                â”‚
â”‚  COMPARACIÃ“N:                                                  â”‚
â”‚                                                                â”‚
â”‚    K-Means:       O(n Ã— k Ã— d Ã— i)                             â”‚
â”‚    Mini-Batch:    O(b Ã— k Ã— d Ã— i)    donde b << n             â”‚
â”‚                                                                â”‚
â”‚    n = datos, k = clusters, d = dimensiones, i = iteraciones   â”‚
â”‚    b = tamaÃ±o del batch                                        â”‚
â”‚                                                                â”‚
â”‚  USAR CUANDO:                                                  â”‚
â”‚    â€¢ Dataset > 10,000 muestras                                 â”‚
â”‚    â€¢ Necesitas resultados rÃ¡pidos                              â”‚
â”‚    â€¢ Puedes tolerar resultado ligeramente subÃ³ptimo            â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ³digo Mini-Batch

```python
from sklearn.cluster import MiniBatchKMeans

# Para datasets grandes
minibatch_kmeans = MiniBatchKMeans(
    n_clusters=5,
    batch_size=100,      # Muestras por batch
    max_iter=100,
    n_init=3,            # Menos inicializaciones (mÃ¡s rÃ¡pido)
    random_state=42
)

labels = minibatch_kmeans.fit_predict(X_scaled)
print(f"Inertia: {minibatch_kmeans.inertia_:.2f}")
```

## 7. Limitaciones de K-Means

### Problemas Conocidos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LIMITACIONES DE K-MEANS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. SOLO CLUSTERS ESFÃ‰RICOS                                    â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚                                                                â”‚
â”‚     Funciona bien:              NO funciona bien:              â”‚
â”‚        â—â—â—     â—‹â—‹â—‹                    â—â—â—â—â—â—â—â—â—â—               â”‚
â”‚       â—â—â—â—    â—‹â—‹â—‹â—‹                   â—â—â—â—â—â—â—â—â—â—â—               â”‚
â”‚        â—â—â—     â—‹â—‹â—‹                  â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹               â”‚
â”‚                                     â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹                â”‚
â”‚                                                                â”‚
â”‚  2. SENSIBLE A OUTLIERS                                        â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚                                                                â”‚
â”‚        â—â—â—â—                          â—â—â—â—                      â”‚
â”‚       â—â—â˜…â—â—                         â—â—â—â—â—          âœ— (outlier) â”‚
â”‚        â—â—â—â—                          â—â—â—â—     â˜…                â”‚
â”‚                                          â†‘                     â”‚
â”‚     Centroide correcto             Centroide arrastrado        â”‚
â”‚                                                                â”‚
â”‚  3. REQUIERE ESPECIFICAR K                                     â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚     No siempre sabemos cuÃ¡ntos clusters hay                    â”‚
â”‚                                                                â”‚
â”‚  4. CLUSTERS DE DIFERENTE TAMAÃ‘O                               â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚     Tiende a crear clusters de tamaÃ±o similar                  â”‚
â”‚                                                                â”‚
â”‚     Datos reales:                 K-Means produce:             â”‚
â”‚        â—â—â—â—â—     â—‹                   â—â—â—     â—â—                â”‚
â”‚       â—â—â—â—â—â—â—                       â—â—â—â—     â—â—â—‹               â”‚
â”‚        â—â—â—â—â—                         â—â—â—â—                      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CuÃ¡ndo NO Usar K-Means

```
NO usar K-Means cuando:

  âœ— Clusters tienen formas irregulares (usar DBSCAN)

  âœ— Hay muchos outliers (usar DBSCAN o preprocesar)

  âœ— Clusters tienen densidades muy diferentes

  âœ— No tienes idea de cuÃ¡ntos clusters hay (usar DBSCAN o jerÃ¡rquico)

  âœ— Features categÃ³ricas (usar K-Modes o K-Prototypes)
```

## 8. Ejemplo PrÃ¡ctico: SegmentaciÃ³n de Ataques

```python
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Simular datos de conexiones de red (posibles ataques)
np.random.seed(42)

# Tipo 1: Conexiones normales (bajo volumen, duraciÃ³n normal)
normal = np.column_stack([
    np.random.normal(100, 30, 500),     # bytes
    np.random.normal(5, 2, 500),        # paquetes
    np.random.normal(10, 3, 500),       # duraciÃ³n (segundos)
    np.random.normal(1, 0.2, 500),      # conexiones por minuto
])

# Tipo 2: Port Scan (muchas conexiones cortas)
portscan = np.column_stack([
    np.random.normal(50, 10, 200),      # bytes (poco)
    np.random.normal(1, 0.3, 200),      # paquetes (poco)
    np.random.normal(0.1, 0.02, 200),   # duraciÃ³n (muy corta)
    np.random.normal(100, 20, 200),     # conexiones por minuto (muchas!)
])

# Tipo 3: DDoS (alto volumen, corta duraciÃ³n)
ddos = np.column_stack([
    np.random.normal(5000, 1000, 150),  # bytes (mucho)
    np.random.normal(100, 20, 150),     # paquetes (muchos)
    np.random.normal(0.5, 0.1, 150),    # duraciÃ³n (corta)
    np.random.normal(50, 10, 150),      # conexiones por minuto (alto)
])

# Tipo 4: Data Exfiltration (alto volumen saliente, larga duraciÃ³n)
exfil = np.column_stack([
    np.random.normal(10000, 2000, 100), # bytes (muy alto)
    np.random.normal(50, 10, 100),      # paquetes
    np.random.normal(300, 60, 100),     # duraciÃ³n (larga)
    np.random.normal(2, 0.5, 100),      # conexiones por minuto (pocas)
])

# Combinar datos
X = np.vstack([normal, portscan, ddos, exfil])
tipos_reales = (['Normal']*500 + ['PortScan']*200 +
                ['DDoS']*150 + ['Exfiltration']*100)

print(f"Total conexiones: {len(X)}")
print(f"Features: bytes, paquetes, duraciÃ³n, conexiones/min")

# Escalar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Encontrar K Ã³ptimo
print("\nBuscando nÃºmero Ã³ptimo de clusters...")
silhouettes = []
inertias = []

for k in range(2, 8):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    silhouettes.append(sil)
    inertias.append(kmeans.inertia_)
    print(f"  K={k}: Silhouette={sil:.3f}, Inertia={kmeans.inertia_:.0f}")

best_k = range(2, 8)[np.argmax(silhouettes)]
print(f"\nMejor K: {best_k}")

# Clustering final
kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_scaled)

# AnÃ¡lisis de resultados
print("\n" + "=" * 70)
print("ANÃLISIS DE CLUSTERS - DETECCIÃ“N DE PATRONES DE ATAQUE")
print("=" * 70)

df = pd.DataFrame(X, columns=['bytes', 'paquetes', 'duracion', 'conn_min'])
df['cluster'] = labels
df['tipo_real'] = tipos_reales

for cluster in range(best_k):
    mask = df['cluster'] == cluster
    n_cluster = mask.sum()

    print(f"\n{'='*50}")
    print(f"CLUSTER {cluster} ({n_cluster} conexiones)")
    print(f"{'='*50}")

    # EstadÃ­sticas
    print("\nCaracterÃ­sticas promedio:")
    print(f"  Bytes/conexiÃ³n:    {df[mask]['bytes'].mean():,.0f}")
    print(f"  Paquetes/conexiÃ³n: {df[mask]['paquetes'].mean():.1f}")
    print(f"  DuraciÃ³n (seg):    {df[mask]['duracion'].mean():.1f}")
    print(f"  Conn/minuto:       {df[mask]['conn_min'].mean():.1f}")

    # ComposiciÃ³n real
    print("\nComposiciÃ³n real:")
    for tipo in df[mask]['tipo_real'].unique():
        count = (df[mask]['tipo_real'] == tipo).sum()
        pct = count / n_cluster * 100
        print(f"  {tipo}: {count} ({pct:.1f}%)")

    # InterpretaciÃ³n automÃ¡tica
    avg_bytes = df[mask]['bytes'].mean()
    avg_conn = df[mask]['conn_min'].mean()
    avg_dur = df[mask]['duracion'].mean()

    if avg_conn > 50 and avg_dur < 1:
        print("\nâš ï¸  PATRÃ“N DETECTADO: Posible PORT SCAN")
        print("   Muchas conexiones muy cortas")
    elif avg_bytes > 3000 and avg_dur < 2:
        print("\nğŸš¨ PATRÃ“N DETECTADO: Posible DDoS")
        print("   Alto volumen en corto tiempo")
    elif avg_bytes > 5000 and avg_dur > 100:
        print("\nğŸ”´ PATRÃ“N DETECTADO: Posible DATA EXFILTRATION")
        print("   Alto volumen saliente sostenido")
    else:
        print("\nâœ… PATRÃ“N: TrÃ¡fico aparentemente normal")

# VisualizaciÃ³n
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(12, 8))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels,
                     cmap='tab10', alpha=0.6, s=50)

# Centroides en espacio PCA
centroids_pca = pca.transform(kmeans.cluster_centers_)
plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1],
           c='red', marker='X', s=200, edgecolors='black',
           linewidth=2, label='Centroides')

plt.colorbar(scatter, label='Cluster')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('SegmentaciÃ³n de TrÃ¡fico de Red (K-Means)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Matriz de confusiÃ³n simplificada
print("\n" + "=" * 70)
print("MATRIZ: CLUSTER vs TIPO REAL")
print("=" * 70)
confusion = pd.crosstab(df['cluster'], df['tipo_real'])
print(confusion)
```

## 9. PredicciÃ³n de Nuevos Datos

```python
# DespuÃ©s de entrenar, predecir nuevos datos
nuevas_conexiones = np.array([
    [80, 3, 8, 1.5],      # Parece normal
    [40, 1, 0.08, 120],   # Parece port scan
    [8000, 150, 0.3, 80], # Parece DDoS
    [15000, 40, 400, 1],  # Parece exfiltraciÃ³n
])

# IMPORTANTE: Escalar con el mismo scaler
nuevas_scaled = scaler.transform(nuevas_conexiones)

# Predecir cluster
predicciones = kmeans.predict(nuevas_scaled)

print("ClasificaciÃ³n de nuevas conexiones:")
for i, (conexion, cluster) in enumerate(zip(nuevas_conexiones, predicciones)):
    print(f"\nConexiÃ³n {i+1}: bytes={conexion[0]:.0f}, "
          f"paquetes={conexion[1]:.0f}, dur={conexion[2]:.1f}s, "
          f"conn/min={conexion[3]:.1f}")
    print(f"  â†’ Cluster {cluster}")
```

## 10. Ventajas y Desventajas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VENTAJAS DE K-MEANS                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ“ Muy rÃ¡pido (O(n Ã— k Ã— d Ã— i))                               â”‚
â”‚  âœ“ Escalable a datasets grandes                                â”‚
â”‚  âœ“ Simple de implementar y entender                            â”‚
â”‚  âœ“ GarantÃ­a de convergencia                                    â”‚
â”‚  âœ“ Funciona bien con clusters esfÃ©ricos                        â”‚
â”‚  âœ“ Resultados interpretables (centroides)                      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DESVENTAJAS DE K-MEANS                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ— Requiere especificar K                                      â”‚
â”‚  âœ— Solo encuentra clusters esfÃ©ricos                           â”‚
â”‚  âœ— Sensible a outliers                                         â”‚
â”‚  âœ— Sensible a la inicializaciÃ³n                                â”‚
â”‚  âœ— Clusters de tamaÃ±o similar                                  â”‚
â”‚  âœ— Solo distancia Euclidiana                                   â”‚
â”‚  âœ— Puede quedar en mÃ­nimo local                                â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 11. Resumen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K-MEANS - RESUMEN                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  ALGORITMO:                                                    â”‚
â”‚    1. Inicializar K centroides (k-means++)                     â”‚
â”‚    2. Asignar puntos al centroide mÃ¡s cercano                  â”‚
â”‚    3. Recalcular centroides como media                         â”‚
â”‚    4. Repetir 2-3 hasta convergencia                           â”‚
â”‚                                                                â”‚
â”‚  HIPERPARÃMETROS:                                              â”‚
â”‚    â€¢ n_clusters: nÃºmero de clusters (K)                        â”‚
â”‚    â€¢ init: 'k-means++' (recomendado)                           â”‚
â”‚    â€¢ n_init: 10 (mÃºltiples inicializaciones)                   â”‚
â”‚                                                                â”‚
â”‚  ELEGIR K:                                                     â”‚
â”‚    â€¢ MÃ©todo del codo (inertia)                                 â”‚
â”‚    â€¢ Silhouette score (recomendado)                            â”‚
â”‚                                                                â”‚
â”‚  PREPROCESAMIENTO:                                             â”‚
â”‚    â€¢ StandardScaler OBLIGATORIO                                â”‚
â”‚                                                                â”‚
â”‚  CUÃNDO USAR:                                                  â”‚
â”‚    âœ“ Clusters esfÃ©ricos esperados                              â”‚
â”‚    âœ“ Conoces K aproximadamente                                 â”‚
â”‚    âœ“ Dataset grande                                            â”‚
â”‚    âœ“ Necesitas rapidez                                         â”‚
â”‚                                                                â”‚
â”‚  CUÃNDO NO USAR:                                               â”‚
â”‚    âœ— Formas irregulares â†’ DBSCAN                               â”‚
â”‚    âœ— Muchos outliers â†’ DBSCAN                                  â”‚
â”‚    âœ— No conoces K â†’ JerÃ¡rquico, DBSCAN                         â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Siguiente:** DBSCAN
