# DBSCAN (Density-Based Spatial Clustering)

## 1. Â¿QuÃ© es DBSCAN?

### Concepto: Clustering Basado en Densidad

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DBSCAN = Density-Based Spatial Clustering of Applications     â”‚
â”‚           with Noise                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  IDEA CENTRAL:                                                 â”‚
â”‚    Clusters = Regiones de ALTA DENSIDAD de puntos              â”‚
â”‚    separadas por regiones de BAJA DENSIDAD                     â”‚
â”‚                                                                â”‚
â”‚       â—â—â—â—â—â—â—                                                  â”‚
â”‚      â—â—â—â—â—â—â—â—           Cluster 1 (alta densidad)              â”‚
â”‚       â—â—â—â—â—â—                                                   â”‚
â”‚                                                                â”‚
â”‚              âœ— â† Outlier (baja densidad)                       â”‚
â”‚                                                                â”‚
â”‚                    â—‹â—‹â—‹â—‹â—‹                                       â”‚
â”‚                   â—‹â—‹â—‹â—‹â—‹â—‹â—‹      Cluster 2 (alta densidad)       â”‚
â”‚                    â—‹â—‹â—‹â—‹â—‹                                       â”‚
â”‚                                                                â”‚
â”‚  VENTAJAS CLAVE:                                               â”‚
â”‚    â€¢ NO requiere especificar nÃºmero de clusters (K)            â”‚
â”‚    â€¢ Detecta clusters de CUALQUIER FORMA                       â”‚
â”‚    â€¢ Identifica automÃ¡ticamente OUTLIERS                       â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DBSCAN vs K-Means

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K-MEANS                          DBSCAN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Solo clusters esfÃ©ricos          Cualquier forma               â”‚
â”‚                                                                 â”‚
â”‚      â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”               â—â—â—â—â—â—â—â—â—â—                    â”‚
â”‚      â”‚â—â—â—â”‚    â”‚â—‹â—‹â—‹â”‚               â—â—â—â—â—â—â—â—â—                     â”‚
â”‚      â”‚â—â—â—â”‚    â”‚â—‹â—‹â—‹â”‚                                             â”‚
â”‚      â””â”€â”€â”€â”˜    â””â”€â”€â”€â”˜                    â—‹â—‹â—‹â—‹â—‹â—‹                   â”‚
â”‚                                       â—‹â—‹â—‹â—‹â—‹â—‹â—‹â—‹                  â”‚
â”‚                                        â—‹â—‹â—‹â—‹â—‹                    â”‚
â”‚                                                                 â”‚
â”‚  Requiere K                       No requiere K                 â”‚
â”‚                                   (lo descubre solo)            â”‚
â”‚                                                                 â”‚
â”‚  No detecta outliers              Detecta outliers              â”‚
â”‚  (todos pertenecen a un cluster)  (etiqueta como -1)            â”‚
â”‚                                                                 â”‚
â”‚        â—â—â—                              â—â—â—                     â”‚
â”‚       â—â—â˜…â—â— â† centroide                â—â—â—â—â—                    â”‚
â”‚        â—â—â—     alejado                  â—â—â—                     â”‚
â”‚              âœ—                               âœ— â† outlier        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. Conceptos Fundamentales

### ParÃ¡metros de DBSCAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DOS PARÃMETROS CLAVE                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Îµ (eps):  Radio de vecindad                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  "Â¿QuÃ© tan lejos puede estar un punto para ser vecino?"        â”‚
â”‚                                                                â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”                                             â”‚
â”‚            â”‚  â—  â”‚ â† puntos dentro del cÃ­rculo                 â”‚
â”‚       â—    â”‚ â—â—â— â”‚   son vecinos                               â”‚
â”‚            â”‚â—â˜…â—â— â”‚                                             â”‚
â”‚            â”‚  â—  â”‚   â˜… = punto central                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”˜   radio = Îµ                                 â”‚
â”‚                                                                â”‚
â”‚  min_samples:  MÃ­nimo de vecinos para ser "core point"         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚  "Â¿CuÃ¡ntos vecinos necesita un punto para formar un cluster?"  â”‚
â”‚                                                                â”‚
â”‚  Si min_samples = 4:                                           â”‚
â”‚                                                                â”‚
â”‚     â—â—â—â—â—  â†’ 5 vecinos â†’ ES core point âœ“                       â”‚
â”‚       â˜…                                                        â”‚
â”‚                                                                â”‚
â”‚     â—â—     â†’ 2 vecinos â†’ NO es core point âœ—                    â”‚
â”‚      â˜…                                                         â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tipos de Puntos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRES TIPOS DE PUNTOS                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. CORE POINT (Punto nÃºcleo)                                  â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚     â€¢ Tiene â‰¥ min_samples vecinos dentro de Îµ                  â”‚
â”‚     â€¢ Forma el "nÃºcleo" del cluster                            â”‚
â”‚                                                                â”‚
â”‚         â—â—â—â—â—                                                  â”‚
â”‚        â—â—â˜…â—â—â—  â† â˜… es core point (muchos vecinos)              â”‚
â”‚         â—â—â—â—                                                   â”‚
â”‚                                                                â”‚
â”‚  2. BORDER POINT (Punto frontera)                              â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚     â€¢ NO tiene min_samples vecinos                             â”‚
â”‚     â€¢ PERO estÃ¡ dentro de Îµ de un core point                   â”‚
â”‚     â€¢ Pertenece al cluster pero en el borde                    â”‚
â”‚                                                                â”‚
â”‚         â—â—â—â—                                                   â”‚
â”‚        â—â—â˜…â—â—   â—‹ â† â—‹ es border point (vecino de core)          â”‚
â”‚         â—â—â—                                                    â”‚
â”‚                                                                â”‚
â”‚  3. NOISE POINT (Outlier)                                      â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚     â€¢ NO tiene min_samples vecinos                             â”‚
â”‚     â€¢ NO estÃ¡ cerca de ningÃºn core point                       â”‚
â”‚     â€¢ Se etiqueta como -1 (no pertenece a ningÃºn cluster)      â”‚
â”‚                                                                â”‚
â”‚         â—â—â—â—                                                   â”‚
â”‚        â—â—â˜…â—â—            âœ— â† âœ— es noise (muy lejos)             â”‚
â”‚         â—â—â—                                                    â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### VisualizaciÃ³n de Tipos

```
           CLUSTER                           OUTLIERS
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â—â—â—â—â—â—â—â—         â”‚
    â”‚   â—â—â—â—â—â—â—â—â—â—   â—‹    â”‚                    âœ—
    â”‚    â—â—â—â—â—â—â—â—    â†‘    â”‚
    â”‚   â—â—â—â—â—â—â—â—â—â—  borderâ”‚        âœ—
    â”‚    â—â—â—â—â—â—â—â—         â”‚
    â”‚        â†‘            â”‚                         âœ—
    â”‚      core           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â— = Core points (muchos vecinos)
    â—‹ = Border points (pocos vecinos pero cerca de core)
    âœ— = Noise/Outliers (aislados)
```

## 3. Algoritmo DBSCAN

### Pasos del Algoritmo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALGORITMO DBSCAN                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. Para cada punto P no visitado:                             â”‚
â”‚     a. Marcar P como visitado                                  â”‚
â”‚     b. Encontrar vecinos de P (puntos a distancia â‰¤ Îµ)         â”‚
â”‚     c. Si |vecinos| < min_samples:                             â”‚
â”‚        â†’ Marcar P como NOISE (temporalmente)                   â”‚
â”‚     d. Si |vecinos| â‰¥ min_samples:                             â”‚
â”‚        â†’ P es CORE POINT                                       â”‚
â”‚        â†’ Crear nuevo cluster C                                 â”‚
â”‚        â†’ AÃ±adir P a C                                          â”‚
â”‚        â†’ Expandir cluster (paso 2)                             â”‚
â”‚                                                                â”‚
â”‚  2. EXPANDIR CLUSTER:                                          â”‚
â”‚     Para cada vecino V de P:                                   â”‚
â”‚     a. Si V no visitado:                                       â”‚
â”‚        â†’ Marcar V como visitado                                â”‚
â”‚        â†’ Si V es core point, aÃ±adir sus vecinos                â”‚
â”‚     b. Si V no pertenece a ningÃºn cluster:                     â”‚
â”‚        â†’ AÃ±adir V al cluster C                                 â”‚
â”‚                                                                â”‚
â”‚  3. Los puntos que quedan como NOISE son outliers              â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### VisualizaciÃ³n del Proceso

```
PASO 1: Identificar core points (min_samples=4, Îµ=radio del cÃ­rculo)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    â—  â—   â—                    â˜…  â˜…   â˜…
      â—  â—    â—        â†’         â˜…  â˜…    â—‹    (â˜… = core, â—‹ = border)
    â—   â—  â—                    â˜…   â˜…  â˜…

              âœ—                           âœ—   (âœ— = noise)


PASO 2: Expandir desde core points (conectar clusters)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    â˜…â”€â”€â˜…â”€â”€â”€â˜…                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â•² â•±                      â”‚ â˜…â”€â”€â˜…â”€â”€â”€â˜…    â”‚
       â˜…â”€â”€â˜…â”€â”€â”€â”€â—‹        â†’      â”‚   â•² â•±       â”‚  = UN cluster
      â•±                        â”‚    â˜…â”€â”€â˜…â”€â”€â”€â”€â—‹â”‚
    â˜…â”€â”€â”€â˜…â”€â”€â˜…                   â”‚   â•±         â”‚
                               â”‚ â˜…â”€â”€â”€â˜…â”€â”€â˜…    â”‚
              âœ—                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         âœ— (sigue siendo noise)


RESULTADO FINAL:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Cluster 0: todos los puntos conectados
    Noise (-1): puntos aislados
```

## 4. ImplementaciÃ³n en Python

### CÃ³digo BÃ¡sico

```python
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import numpy as np

# Generar datos con diferentes formas
np.random.seed(42)

# Dos clusters con forma de media luna
from sklearn.datasets import make_moons
X, _ = make_moons(n_samples=300, noise=0.05)

# AÃ±adir outliers
outliers = np.random.uniform(-2, 3, (20, 2))
X = np.vstack([X, outliers])

# IMPORTANTE: Escalar datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# DBSCAN
dbscan = DBSCAN(
    eps=0.3,          # Radio de vecindad
    min_samples=5,    # MÃ­nimo de vecinos para core point
    metric='euclidean'
)

labels = dbscan.fit_predict(X_scaled)

# Resultados
n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
n_noise = (labels == -1).sum()

print(f"Clusters encontrados: {n_clusters}")
print(f"Puntos de ruido (outliers): {n_noise}")
print(f"Core samples: {len(dbscan.core_sample_indices_)}")
```

### VisualizaciÃ³n

```python
import matplotlib.pyplot as plt

def plot_dbscan(X, labels, title="DBSCAN Clustering"):
    plt.figure(figsize=(12, 8))

    # Colores: -1 (noise) en negro
    unique_labels = set(labels)
    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))

    for label, color in zip(unique_labels, colors):
        if label == -1:
            # Outliers en negro con X
            color = 'black'
            marker = 'x'
            size = 50
            alpha = 0.6
        else:
            marker = 'o'
            size = 50
            alpha = 0.8

        mask = labels == label
        plt.scatter(X[mask, 0], X[mask, 1],
                   c=[color], marker=marker, s=size,
                   alpha=alpha, label=f'Cluster {label}' if label != -1 else 'Noise')

    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

plot_dbscan(X_scaled, labels)
```

## 5. Elegir los ParÃ¡metros

### El Problema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ELEGIR eps Y min_samples ES CRÃTICO                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  eps MUY PEQUEÃ‘O:              eps MUY GRANDE:                 â”‚
â”‚                                                                â”‚
â”‚    â—  â—  â—  â—                     â—â—â—â—â—â—â—â—â—â—                   â”‚
â”‚    â—  â—  â—  â—                    â—â—â—â—â—â—â—â—â—â—â—                   â”‚
â”‚    â—  â—  â—  â—                     â—â—â—â—â—â—â—â—â—                    â”‚
â”‚                                                                â”‚
â”‚   Muchos clusters pequeÃ±os        Un solo cluster gigante      â”‚
â”‚   o todo es noise                                              â”‚
â”‚                                                                â”‚
â”‚  min_samples MUY BAJO:         min_samples MUY ALTO:           â”‚
â”‚                                                                â”‚
â”‚    Todo es cluster              Todo es noise                  â”‚
â”‚    (incluso outliers)           (nada tiene suficientes        â”‚
â”‚                                  vecinos)                      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©todo del K-Distance Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰TODO K-DISTANCE PARA ELEGIR eps                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. Elegir k = min_samples (o min_samples - 1)                 â”‚
â”‚                                                                â”‚
â”‚  2. Para cada punto, calcular distancia al k-Ã©simo vecino      â”‚
â”‚                                                                â”‚
â”‚  3. Ordenar distancias de menor a mayor y graficar             â”‚
â”‚                                                                â”‚
â”‚  4. Buscar el "codo" en el grÃ¡fico                             â”‚
â”‚                                                                â”‚
â”‚  k-distance                                                    â”‚
â”‚     â”‚                                                          â”‚
â”‚     â”‚                               â•±                          â”‚
â”‚     â”‚                          â•±â”€â”€â”€â•±                           â”‚
â”‚     â”‚                     ____â•±                                â”‚
â”‚     â”‚               _____â•±                                     â”‚
â”‚     â”‚          ____â•±  â† CODO (eps Ã³ptimo)                      â”‚
â”‚     â”‚_________â•±                                                â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ puntos (ordenados)       â”‚
â”‚                                                                â”‚
â”‚  El codo indica donde la densidad cambia significativamente    â”‚
â”‚  eps â‰ˆ valor de k-distance en el codo                          â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ³digo: Encontrar eps Ã“ptimo

```python
from sklearn.neighbors import NearestNeighbors
import numpy as np
import matplotlib.pyplot as plt

def find_optimal_eps(X, min_samples=5):
    """Encuentra eps Ã³ptimo usando k-distance graph"""

    # Calcular distancias al k-Ã©simo vecino
    k = min_samples
    neighbors = NearestNeighbors(n_neighbors=k)
    neighbors.fit(X)
    distances, _ = neighbors.kneighbors(X)

    # Distancia al k-Ã©simo vecino (Ãºltima columna)
    k_distances = distances[:, -1]

    # Ordenar
    k_distances_sorted = np.sort(k_distances)

    # Graficar
    plt.figure(figsize=(10, 6))
    plt.plot(range(len(k_distances_sorted)), k_distances_sorted, 'b-')
    plt.xlabel('Puntos ordenados')
    plt.ylabel(f'Distancia al {k}-Ã©simo vecino')
    plt.title('K-Distance Graph para elegir eps')
    plt.grid(True, alpha=0.3)

    # AÃ±adir lÃ­nea horizontal sugerida (heurÃ­stica)
    # Buscar el punto de mÃ¡xima curvatura
    from scipy.ndimage import gaussian_filter1d
    smoothed = gaussian_filter1d(k_distances_sorted, sigma=len(k_distances)//50)
    second_derivative = np.diff(np.diff(smoothed))
    elbow_idx = np.argmax(second_derivative) + 2
    suggested_eps = k_distances_sorted[elbow_idx]

    plt.axhline(y=suggested_eps, color='r', linestyle='--',
                label=f'eps sugerido â‰ˆ {suggested_eps:.3f}')
    plt.legend()
    plt.show()

    return suggested_eps

# Uso
optimal_eps = find_optimal_eps(X_scaled, min_samples=5)
print(f"eps sugerido: {optimal_eps:.3f}")
```

### GuÃ­a para min_samples

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REGLAS PARA min_samples                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  REGLA GENERAL:                                                â”‚
â”‚    min_samples â‰¥ dimensiones + 1                               â”‚
â”‚    (mÃ­nimo para definir un hiperplano)                         â”‚
â”‚                                                                â”‚
â”‚  REGLAS PRÃCTICAS:                                             â”‚
â”‚                                                                â”‚
â”‚    â€¢ Datos 2D: min_samples = 4-5                               â”‚
â”‚    â€¢ Datos alta dimensiÃ³n: min_samples = 2 Ã— dim               â”‚
â”‚    â€¢ Datos con mucho ruido: aumentar min_samples               â”‚
â”‚    â€¢ Clusters pequeÃ±os esperados: reducir min_samples          â”‚
â”‚                                                                â”‚
â”‚  EJEMPLO:                                                      â”‚
â”‚    Dataset con 10 features:                                    â”‚
â”‚    min_samples = 10 + 1 = 11 (mÃ­nimo)                          â”‚
â”‚    min_samples = 2 Ã— 10 = 20 (conservador)                     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### BÃºsqueda de ParÃ¡metros

```python
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
import numpy as np

def search_dbscan_params(X, eps_range, min_samples_range):
    """Busca mejores parÃ¡metros para DBSCAN"""

    best_score = -1
    best_params = None
    results = []

    for eps in eps_range:
        for min_samples in min_samples_range:
            dbscan = DBSCAN(eps=eps, min_samples=min_samples)
            labels = dbscan.fit_predict(X)

            # Ignorar si todo es noise o un solo cluster
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            n_noise = (labels == -1).sum()

            if n_clusters >= 2 and n_noise < len(X) * 0.5:
                # Calcular silhouette solo para puntos no-noise
                mask = labels != -1
                if mask.sum() > 0:
                    score = silhouette_score(X[mask], labels[mask])
                    results.append({
                        'eps': eps,
                        'min_samples': min_samples,
                        'n_clusters': n_clusters,
                        'n_noise': n_noise,
                        'silhouette': score
                    })

                    if score > best_score:
                        best_score = score
                        best_params = (eps, min_samples)

    return best_params, results

# Uso
eps_range = np.arange(0.1, 1.0, 0.1)
min_samples_range = range(3, 10)

best_params, results = search_dbscan_params(X_scaled, eps_range, min_samples_range)
print(f"Mejores parÃ¡metros: eps={best_params[0]:.2f}, min_samples={best_params[1]}")
```

## 6. HDBSCAN: VersiÃ³n Mejorada

### Limitaciones de DBSCAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROBLEMA DE DBSCAN: Clusters con diferente densidad           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Datos con densidad variable:                                  â”‚
â”‚                                                                â”‚
â”‚      â—â—â—â—â—â—â—â—                      â—‹  â—‹                        â”‚
â”‚     â—â—â—â—â—â—â—â—â—â—                    â—‹    â—‹                       â”‚
â”‚      â—â—â—â—â—â—â—â—                      â—‹  â—‹                        â”‚
â”‚     â—â—â—â—â—â—â—â—â—â—                                                 â”‚
â”‚      â—â—â—â—â—â—â—â—                                                  â”‚
â”‚                                                                â”‚
â”‚    Cluster DENSO                Cluster DISPERSO               â”‚
â”‚                                                                â”‚
â”‚  Con un solo eps:                                              â”‚
â”‚    - eps pequeÃ±o: detecta denso, disperso es todo noise        â”‚
â”‚    - eps grande: une ambos en un solo cluster                  â”‚
â”‚                                                                â”‚
â”‚  SOLUCIÃ“N: HDBSCAN (Hierarchical DBSCAN)                       â”‚
â”‚    - No requiere eps fijo                                      â”‚
â”‚    - Maneja clusters de diferente densidad                     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### HDBSCAN en Python

```python
# pip install hdbscan
import hdbscan

# HDBSCAN no requiere eps
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=5,     # TamaÃ±o mÃ­nimo de cluster
    min_samples=3,          # Como DBSCAN
    cluster_selection_epsilon=0.0,
    metric='euclidean'
)

labels = clusterer.fit_predict(X_scaled)

# HDBSCAN proporciona probabilidades de pertenencia
probabilities = clusterer.probabilities_

print(f"Clusters: {len(set(labels)) - (1 if -1 in labels else 0)}")
print(f"Noise: {(labels == -1).sum()}")

# Visualizar con intensidad por probabilidad
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_scaled[:, 0], X_scaled[:, 1],
                     c=labels, cmap='viridis',
                     alpha=probabilities)
plt.colorbar(scatter)
plt.title('HDBSCAN Clustering')
plt.show()
```

## 7. Ejemplo PrÃ¡ctico: DetecciÃ³n de AnomalÃ­as en Red

```python
import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt

# Simular trÃ¡fico de red
np.random.seed(42)

# TrÃ¡fico normal (cluster grande y denso)
normal = np.column_stack([
    np.random.normal(100, 20, 800),     # bytes
    np.random.normal(5, 1, 800),        # paquetes/seg
    np.random.normal(443, 10, 800),     # puerto (HTTPS)
])

# TrÃ¡fico de backup (cluster pequeÃ±o, diferente patrÃ³n)
backup = np.column_stack([
    np.random.normal(5000, 500, 100),   # muchos bytes
    np.random.normal(50, 10, 100),      # muchos paquetes
    np.random.normal(22, 1, 100),       # SSH
])

# AnomalÃ­as (outliers dispersos)
anomalias = np.column_stack([
    np.random.uniform(0, 10000, 30),    # bytes aleatorios
    np.random.uniform(0, 100, 30),      # paquetes aleatorios
    np.random.uniform(1, 65535, 30),    # puertos aleatorios
])

# Combinar
X = np.vstack([normal, backup, anomalias])
tipos = ['Normal']*800 + ['Backup']*100 + ['AnomalÃ­a']*30

print(f"Total conexiones: {len(X)}")
print(f"  Normal: 800")
print(f"  Backup: 100")
print(f"  AnomalÃ­as: 30")

# Escalar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Encontrar eps Ã³ptimo
print("\nBuscando eps Ã³ptimo...")
k = 5
neighbors = NearestNeighbors(n_neighbors=k)
neighbors.fit(X_scaled)
distances, _ = neighbors.kneighbors(X_scaled)
k_distances = np.sort(distances[:, -1])

# Visualizar k-distance
plt.figure(figsize=(10, 5))
plt.plot(k_distances)
plt.xlabel('Puntos ordenados')
plt.ylabel(f'Distancia al {k}-Ã©simo vecino')
plt.title('K-Distance Graph')
plt.grid(True, alpha=0.3)
plt.show()

# DBSCAN
eps = 0.5  # Ajustar segÃºn el grÃ¡fico
dbscan = DBSCAN(eps=eps, min_samples=5)
labels = dbscan.fit_predict(X_scaled)

# Resultados
n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
n_noise = (labels == -1).sum()

print(f"\nResultados DBSCAN (eps={eps}):")
print(f"  Clusters detectados: {n_clusters}")
print(f"  Puntos de ruido (anomalÃ­as): {n_noise}")

# Analizar
df = pd.DataFrame(X, columns=['bytes', 'paquetes', 'puerto'])
df['cluster'] = labels
df['tipo_real'] = tipos

print("\n" + "=" * 60)
print("ANÃLISIS DE DETECCIÃ“N DE ANOMALÃAS")
print("=" * 60)

# AnÃ¡lisis por cluster
for cluster in sorted(df['cluster'].unique()):
    mask = df['cluster'] == cluster
    n = mask.sum()

    if cluster == -1:
        print(f"\nğŸš¨ ANOMALÃAS DETECTADAS ({n} conexiones):")
    else:
        print(f"\nCluster {cluster} ({n} conexiones):")

    # EstadÃ­sticas
    print(f"  Bytes promedio: {df[mask]['bytes'].mean():,.0f}")
    print(f"  Paquetes/seg: {df[mask]['paquetes'].mean():.1f}")
    print(f"  Puerto mÃ¡s comÃºn: {df[mask]['puerto'].mode().values[0]:.0f}")

    # ComposiciÃ³n real
    print(f"  Tipos reales:")
    for tipo in df[mask]['tipo_real'].value_counts().items():
        print(f"    - {tipo[0]}: {tipo[1]} ({tipo[1]/n*100:.1f}%)")

# MÃ©tricas de detecciÃ³n
anomalias_detectadas = ((df['cluster'] == -1) & (df['tipo_real'] == 'AnomalÃ­a')).sum()
anomalias_totales = (df['tipo_real'] == 'AnomalÃ­a').sum()
falsos_positivos = ((df['cluster'] == -1) & (df['tipo_real'] != 'AnomalÃ­a')).sum()

print("\n" + "=" * 60)
print("MÃ‰TRICAS DE DETECCIÃ“N")
print("=" * 60)
print(f"AnomalÃ­as reales detectadas: {anomalias_detectadas}/{anomalias_totales} "
      f"({anomalias_detectadas/anomalias_totales*100:.1f}%)")
print(f"Falsos positivos: {falsos_positivos}")
print(f"Precision: {anomalias_detectadas/(anomalias_detectadas+falsos_positivos)*100:.1f}%"
      if (anomalias_detectadas+falsos_positivos) > 0 else "N/A")

# VisualizaciÃ³n
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(12, 8))

# Clusters normales
for cluster in sorted(set(labels)):
    if cluster == -1:
        continue
    mask = labels == cluster
    plt.scatter(X_pca[mask, 0], X_pca[mask, 1],
               alpha=0.6, s=50, label=f'Cluster {cluster}')

# AnomalÃ­as
mask = labels == -1
plt.scatter(X_pca[mask, 0], X_pca[mask, 1],
           c='red', marker='x', s=100, linewidths=2,
           label=f'AnomalÃ­as ({mask.sum()})')

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('DetecciÃ³n de AnomalÃ­as con DBSCAN')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

## 8. Ventajas y Desventajas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VENTAJAS DE DBSCAN                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ“ NO requiere especificar nÃºmero de clusters                  â”‚
â”‚  âœ“ Encuentra clusters de CUALQUIER forma                       â”‚
â”‚  âœ“ Detecta OUTLIERS automÃ¡ticamente                            â”‚
â”‚  âœ“ Robusto al ruido                                            â”‚
â”‚  âœ“ Solo dos parÃ¡metros (eps, min_samples)                      â”‚
â”‚  âœ“ No asume distribuciÃ³n de datos                              â”‚
â”‚  âœ“ Eficiente con Ã­ndices espaciales (O(n log n))              â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DESVENTAJAS DE DBSCAN                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ— Sensible a la elecciÃ³n de eps y min_samples                 â”‚
â”‚  âœ— Mal desempeÃ±o con densidades muy diferentes                 â”‚
â”‚  âœ— No funciona bien en alta dimensiÃ³n (curse of dim)           â”‚
â”‚  âœ— Lento para datasets muy grandes sin optimizaciÃ³n            â”‚
â”‚  âœ— No asigna nuevos puntos (necesita re-entrenar)              â”‚
â”‚  âœ— Resultados pueden variar con orden de datos                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 9. CuÃ¡ndo Usar DBSCAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CASOS DE USO IDEALES                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ“ DetecciÃ³n de anomalÃ­as / outliers                           â”‚
â”‚  âœ“ No sabes cuÃ¡ntos clusters hay                               â”‚
â”‚  âœ“ Clusters con formas irregulares                             â”‚
â”‚  âœ“ Datos geoespaciales                                         â”‚
â”‚  âœ“ SegmentaciÃ³n de imÃ¡genes                                    â”‚
â”‚  âœ“ AgrupaciÃ³n de comportamientos en logs                       â”‚
â”‚                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EVITAR CUANDO                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ— Clusters tienen densidades muy diferentes (usar HDBSCAN)    â”‚
â”‚  âœ— Datos de muy alta dimensiÃ³n (>20 features)                  â”‚
â”‚  âœ— Necesitas asignar nuevos puntos frecuentemente              â”‚
â”‚  âœ— Clusters esfÃ©ricos y sabes K (usar K-Means, mÃ¡s rÃ¡pido)     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 10. Resumen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DBSCAN - RESUMEN                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  CONCEPTO:                                                     â”‚
â”‚    Clusters = regiones de alta densidad                        â”‚
â”‚    Outliers = puntos en regiones de baja densidad              â”‚
â”‚                                                                â”‚
â”‚  PARÃMETROS:                                                   â”‚
â”‚    â€¢ eps: radio de vecindad                                    â”‚
â”‚    â€¢ min_samples: mÃ­nimo de vecinos para core point            â”‚
â”‚                                                                â”‚
â”‚  TIPOS DE PUNTOS:                                              â”‚
â”‚    â€¢ Core: â‰¥ min_samples vecinos                               â”‚
â”‚    â€¢ Border: vecino de core pero < min_samples vecinos         â”‚
â”‚    â€¢ Noise: ni core ni border (etiqueta -1)                    â”‚
â”‚                                                                â”‚
â”‚  ELEGIR PARÃMETROS:                                            â”‚
â”‚    â€¢ eps: k-distance graph (buscar codo)                       â”‚
â”‚    â€¢ min_samples: dim + 1 o 2 Ã— dim                            â”‚
â”‚                                                                â”‚
â”‚  EN CIBERSEGURIDAD:                                            â”‚
â”‚    â€¢ DetecciÃ³n de anomalÃ­as en trÃ¡fico                         â”‚
â”‚    â€¢ Identificar comportamientos anÃ³malos                      â”‚
â”‚    â€¢ Filtrar ruido en logs                                     â”‚
â”‚    â€¢ Agrupar eventos de seguridad                              â”‚
â”‚                                                                â”‚
â”‚  ALTERNATIVAS:                                                 â”‚
â”‚    â€¢ HDBSCAN: para densidades variables                        â”‚
â”‚    â€¢ OPTICS: para visualizar estructura de densidad            â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Siguiente:** Clustering JerÃ¡rquico
