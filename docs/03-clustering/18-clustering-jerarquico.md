# Clustering JerÃ¡rquico

## 1. Â¿QuÃ© es Clustering JerÃ¡rquico?

### Concepto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLUSTERING JERÃRQUICO                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Crea una JERARQUÃA de clusters (Ã¡rbol)                        â”‚
â”‚  NO requiere especificar K de antemano                         â”‚
â”‚                                                                â”‚
â”‚  DOS ENFOQUES:                                                 â”‚
â”‚                                                                â”‚
â”‚  AGLOMERATIVO (Bottom-Up):                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  â€¢ Empieza: cada punto es un cluster                           â”‚
â”‚  â€¢ IteraciÃ³n: une los dos clusters mÃ¡s cercanos                â”‚
â”‚  â€¢ Termina: todo en un solo cluster                            â”‚
â”‚                                                                â”‚
â”‚       A  B  C  D  E       â†’      (AB) (CDE)     â†’   ((AB)(CDE))â”‚
â”‚       â”‚  â”‚  â”‚  â”‚  â”‚              â•±  â•²  â”‚  â•²           â”‚        â”‚
â”‚       cada uno solo          se unen los mÃ¡s        un solo    â”‚
â”‚                              cercanos              cluster     â”‚
â”‚                                                                â”‚
â”‚  DIVISIVO (Top-Down):                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  â€¢ Empieza: todos en un cluster                                â”‚
â”‚  â€¢ IteraciÃ³n: divide el cluster mÃ¡s heterogÃ©neo                â”‚
â”‚  â€¢ Termina: cada punto es un cluster                           â”‚
â”‚                                                                â”‚
â”‚  (Aglomerativo es mucho mÃ¡s comÃºn)                             â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dendrograma

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DENDROGRAMA = VisualizaciÃ³n del proceso jerÃ¡rquico            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Distancia                                                     â”‚
â”‚     â”‚                                                          â”‚
â”‚  5  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚     â”‚              â”‚                 â”‚                         â”‚
â”‚  4  â”‚        â”Œâ”€â”€â”€â”€â”€â”˜           â”Œâ”€â”€â”€â”€â”€â”˜                         â”‚
â”‚     â”‚        â”‚                 â”‚                               â”‚
â”‚  3  â”‚   â”Œâ”€â”€â”€â”€â”˜            â”Œâ”€â”€â”€â”€â”˜                               â”‚
â”‚     â”‚   â”‚                 â”‚                                    â”‚
â”‚  2  â”‚ â”Œâ”€â”˜           â”Œâ”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚     â”‚ â”‚             â”‚                                          â”‚
â”‚  1  â”‚â”€â”˜       â”Œâ”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚     â”‚         â”‚                                                â”‚
â”‚  0  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚       A   B   C   D   E   F   G   H                            â”‚
â”‚                                                                â”‚
â”‚  CÃ³mo leer:                                                    â”‚
â”‚    â€¢ Eje Y = distancia a la que se unen clusters               â”‚
â”‚    â€¢ LÃ­neas verticales = clusters                              â”‚
â”‚    â€¢ LÃ­neas horizontales = uniÃ³n de clusters                   â”‚
â”‚    â€¢ Cortar horizontalmente da diferentes K                    â”‚
â”‚                                                                â”‚
â”‚  Corte en distancia 3:                                         â”‚
â”‚    â†’ Cluster 1: {A, B}                                         â”‚
â”‚    â†’ Cluster 2: {C, D, E}                                      â”‚
â”‚    â†’ Cluster 3: {F, G, H}                                      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. MÃ©todos de Linkage

### Tipos de Linkage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LINKAGE = CÃ³mo medir distancia entre CLUSTERS                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. SINGLE LINKAGE (MÃ­nimo)                                    â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚     Distancia = mÃ­nima entre cualquier par de puntos           â”‚
â”‚                                                                â”‚
â”‚        Cluster A        Cluster B                              â”‚
â”‚         â—  â—              â—‹  â—‹                                 â”‚
â”‚        â—    â—â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â—‹    â—‹                                â”‚
â”‚         â—  â—         d    â—‹  â—‹                                 â”‚
â”‚                       â†‘                                        â”‚
â”‚               Distancia mÃ¡s corta                              â”‚
â”‚                                                                â”‚
â”‚     Pro: Encuentra clusters alargados                          â”‚
â”‚     Con: "Efecto cadena" - une clusters que no deberÃ­an        â”‚
â”‚                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  2. COMPLETE LINKAGE (MÃ¡ximo)                                  â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚     Distancia = mÃ¡xima entre cualquier par de puntos           â”‚
â”‚                                                                â”‚
â”‚        â—â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â—‹                                â”‚
â”‚         â†–                   â†—                                  â”‚
â”‚          â—  â—          â—‹  â—‹                                    â”‚
â”‚         â—    â—        â—‹    â—‹                                   â”‚
â”‚          â—  â—          â—‹  â—‹                                    â”‚
â”‚               d = distancia mÃ¡s larga                          â”‚
â”‚                                                                â”‚
â”‚     Pro: Clusters compactos y esfÃ©ricos                        â”‚
â”‚     Con: Sensible a outliers                                   â”‚
â”‚                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  3. AVERAGE LINKAGE (UPGMA)                                    â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚     Distancia = promedio de todas las distancias               â”‚
â”‚                                                                â”‚
â”‚          â—  â—          â—‹  â—‹                                    â”‚
â”‚         â—â‚  â—áµ¦   âŸ·    â—‹áµ§  â—‹Î´                                  â”‚
â”‚          â—  â—          â—‹  â—‹                                    â”‚
â”‚                                                                â”‚
â”‚     d = (d(a,Î³) + d(a,Î´) + d(Î²,Î³) + d(Î²,Î´) + ...) / n         â”‚
â”‚                                                                â”‚
â”‚     Pro: Balance entre single y complete                       â”‚
â”‚     Con: Puede ser lento                                       â”‚
â”‚                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  4. WARD'S METHOD                                              â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚     Minimiza el incremento de varianza al unir clusters        â”‚
â”‚                                                                â”‚
â”‚     Unir clusters que aumenten MENOS la varianza intra-cluster â”‚
â”‚                                                                â”‚
â”‚     Pro: Tiende a crear clusters de tamaÃ±o similar             â”‚
â”‚     Con: Asume clusters esfÃ©ricos                              â”‚
â”‚     â˜… MÃ¡s usado en la prÃ¡ctica                                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ComparaciÃ³n Visual

```
SINGLE LINKAGE:              COMPLETE LINKAGE:           WARD:
(une mÃ¡s fÃ¡cilmente)         (clusters compactos)        (tamaÃ±o similar)

     â—â—â—â—â—â—â—â—â—â—                  â—â—â—   â—â—â—                 â—â—â—â—   â—â—â—â—
    â—â—â—â—â—â—â—â—â—â—â—                 â—â—â—â—â— â—â—â—â—â—               â—â—â—â—â— â—â—â—â—â—
     â—â—â—â—â—â—â—â—â—â—                  â—â—â—   â—â—â—                 â—â—â—â—   â—â—â—â—
          â†“
    Puede crear "cadenas"      Clusters bien             Clusters
    de un solo cluster         separados                 balanceados
```

## 3. Algoritmo Aglomerativo

### Pasos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALGORITMO CLUSTERING AGLOMERATIVO                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  ENTRADA:                                                      â”‚
â”‚    â€¢ N puntos                                                  â”‚
â”‚    â€¢ MÃ©todo de linkage                                         â”‚
â”‚    â€¢ MÃ©trica de distancia                                      â”‚
â”‚                                                                â”‚
â”‚  ALGORITMO:                                                    â”‚
â”‚                                                                â”‚
â”‚  1. Inicializar: cada punto es un cluster (N clusters)         â”‚
â”‚                                                                â”‚
â”‚  2. Calcular matriz de distancias entre todos los clusters     â”‚
â”‚                                                                â”‚
â”‚  3. MIENTRAS nÃºmero de clusters > 1:                           â”‚
â”‚     a. Encontrar los dos clusters mÃ¡s cercanos                 â”‚
â”‚     b. Unirlos en un nuevo cluster                             â”‚
â”‚     c. Actualizar matriz de distancias                         â”‚
â”‚                                                                â”‚
â”‚  4. Construir dendrograma                                      â”‚
â”‚                                                                â”‚
â”‚  COMPLEJIDAD:                                                  â”‚
â”‚    â€¢ Tiempo: O(nÂ³) o O(nÂ² log n) con optimizaciones            â”‚
â”‚    â€¢ Espacio: O(nÂ²) para matriz de distancias                  â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo Paso a Paso

```
DATOS: A, B, C, D, E (5 puntos)

PASO 0: Matriz de distancias inicial
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        A    B    C    D    E
   A    0    2    6    10   9
   B    2    0    5    9    8
   C    6    5    0    4    5
   D    10   9    4    0    3
   E    9    8    5    3    0

PASO 1: Unir A y B (distancia = 2, la mÃ­nima)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Clusters: {A,B}, {C}, {D}, {E}

        AB   C    D    E
  AB    0    5    9    8     â† Recalcular distancias
   C    5    0    4    5       (usando linkage elegido)
   D    9    4    0    3
   E    8    5    3    0

PASO 2: Unir D y E (distancia = 3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Clusters: {A,B}, {C}, {D,E}

        AB   C    DE
  AB    0    5    8
   C    5    0    4
  DE    8    4    0

PASO 3: Unir C y DE (distancia = 4)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Clusters: {A,B}, {C,D,E}

        AB   CDE
  AB    0    5
 CDE    5    0

PASO 4: Unir AB y CDE (distancia = 5)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Cluster final: {A,B,C,D,E}

DENDROGRAMA:
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
          5         â”‚        â”‚
                â”Œâ”€â”€â”€â”˜    â”Œâ”€â”€â”€â”˜
          4     â”‚   â”Œâ”€â”€â”€â”€â”˜
                â”‚   â”‚
          3     â”‚ â”Œâ”€â”˜
          2   â”Œâ”€â”˜ â”‚
              â”‚   â”‚
          0   A B C D E
```

## 4. ImplementaciÃ³n en Python

### CÃ³digo BÃ¡sico

```python
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt

# Generar datos
np.random.seed(42)
X = np.vstack([
    np.random.randn(30, 2) + [0, 0],
    np.random.randn(30, 2) + [5, 5],
    np.random.randn(30, 2) + [10, 0],
])

# Escalar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Clustering JerÃ¡rquico con sklearn
agg = AgglomerativeClustering(
    n_clusters=3,          # Si conoces K
    # n_clusters=None,     # Si no conoces K
    # distance_threshold=5, # Cortar en distancia
    linkage='ward',        # 'single', 'complete', 'average', 'ward'
    metric='euclidean'
)

labels = agg.fit_predict(X_scaled)

print(f"Clusters encontrados: {len(set(labels))}")
print(f"DistribuciÃ³n: {np.bincount(labels)}")
```

### Crear Dendrograma

```python
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

def plot_dendrogram(X, method='ward', title="Dendrograma"):
    """Crea y visualiza un dendrograma"""

    # Calcular linkage
    Z = linkage(X, method=method)

    # Crear figura
    plt.figure(figsize=(12, 8))

    # Dendrograma
    dendrogram(
        Z,
        truncate_mode='level',    # 'lastp' o 'level' para grandes datasets
        p=30,                      # Mostrar mÃ¡ximo 30 hojas
        leaf_rotation=90,
        leaf_font_size=8,
        show_contracted=True
    )

    plt.xlabel('Ãndice de muestra (o tamaÃ±o del cluster)')
    plt.ylabel('Distancia')
    plt.title(f'{title} (linkage={method})')
    plt.tight_layout()
    plt.show()

    return Z

# Crear dendrograma
Z = plot_dendrogram(X_scaled, method='ward')
```

### Elegir NÃºmero de Clusters

```python
from scipy.cluster.hierarchy import fcluster

def analizar_cortes(Z, X, max_k=10):
    """Analiza diferentes cortes del dendrograma"""

    from sklearn.metrics import silhouette_score

    scores = []

    for k in range(2, max_k + 1):
        # Cortar dendrograma para obtener k clusters
        labels = fcluster(Z, k, criterion='maxclust')

        # Calcular silhouette
        score = silhouette_score(X, labels)
        scores.append((k, score))
        print(f"K={k}: Silhouette={score:.3f}")

    # Mejor K
    best_k = max(scores, key=lambda x: x[1])[0]
    print(f"\nMejor K segÃºn Silhouette: {best_k}")

    # Visualizar
    plt.figure(figsize=(10, 5))
    plt.plot([s[0] for s in scores], [s[1] for s in scores], 'bo-')
    plt.xlabel('NÃºmero de clusters (K)')
    plt.ylabel('Silhouette Score')
    plt.title('AnÃ¡lisis de Cortes del Dendrograma')
    plt.grid(True, alpha=0.3)
    plt.show()

    return best_k

best_k = analizar_cortes(Z, X_scaled)
```

### Cortar el Dendrograma

```python
from scipy.cluster.hierarchy import fcluster

# MÃ©todo 1: Por nÃºmero de clusters
labels = fcluster(Z, t=3, criterion='maxclust')  # 3 clusters

# MÃ©todo 2: Por distancia
labels = fcluster(Z, t=5.0, criterion='distance')  # Cortar en distancia 5

# MÃ©todo 3: Por inconsistencia (automÃ¡tico)
labels = fcluster(Z, t=1.5, criterion='inconsistent')

# Visualizar resultado
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis')
plt.colorbar(scatter, label='Cluster')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Clustering JerÃ¡rquico')
plt.show()
```

## 5. ComparaciÃ³n de Linkages

```python
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

def comparar_linkages(X, n_clusters=3):
    """Compara diferentes mÃ©todos de linkage"""

    linkages = ['single', 'complete', 'average', 'ward']

    fig, axes = plt.subplots(2, 4, figsize=(20, 10))

    for i, method in enumerate(linkages):
        # Dendrograma
        Z = linkage(X, method=method)
        ax_dend = axes[0, i]
        dendrogram(Z, ax=ax_dend, truncate_mode='level', p=10)
        ax_dend.set_title(f'{method.upper()} Linkage')
        ax_dend.set_xlabel('')

        # Clustering
        if method == 'ward':
            metric = 'euclidean'
        else:
            metric = 'euclidean'

        agg = AgglomerativeClustering(
            n_clusters=n_clusters,
            linkage=method,
            metric=metric
        )
        labels = agg.fit_predict(X)

        ax_cluster = axes[1, i]
        scatter = ax_cluster.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
        ax_cluster.set_title(f'Clusters ({method})')

    plt.tight_layout()
    plt.show()

# Uso
comparar_linkages(X_scaled)
```

## 6. Ejemplo PrÃ¡ctico: AgrupaciÃ³n de Malware

```python
import numpy as np
import pandas as pd
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Simular caracterÃ­sticas de muestras de malware
np.random.seed(42)

# Familia 1: Ransomware (cifrado, pocos archivos, rÃ¡pido)
ransomware = np.column_stack([
    np.random.normal(0.9, 0.1, 40),    # uso_crypto (alto)
    np.random.normal(100, 20, 40),     # archivos_modificados
    np.random.normal(5, 1, 40),        # tiempo_ejecucion (seg)
    np.random.normal(0.1, 0.05, 40),   # trafico_red (bajo)
    np.random.normal(0.8, 0.1, 40),    # persistencia
])

# Familia 2: Spyware (poco cifrado, monitoreo largo, red moderada)
spyware = np.column_stack([
    np.random.normal(0.2, 0.1, 35),    # uso_crypto (bajo)
    np.random.normal(10, 5, 35),       # archivos_modificados (pocos)
    np.random.normal(3600, 600, 35),   # tiempo_ejecucion (largo)
    np.random.normal(0.5, 0.1, 35),    # trafico_red (moderado)
    np.random.normal(0.9, 0.05, 35),   # persistencia (alto)
])

# Familia 3: Botnet (poco cifrado, ejecuciÃ³n variable, mucha red)
botnet = np.column_stack([
    np.random.normal(0.3, 0.1, 45),    # uso_crypto
    np.random.normal(5, 2, 45),        # archivos_modificados
    np.random.normal(7200, 1000, 45),  # tiempo_ejecucion (muy largo)
    np.random.normal(0.9, 0.1, 45),    # trafico_red (alto)
    np.random.normal(0.95, 0.03, 45),  # persistencia (muy alto)
])

# Familia 4: Cryptominer (alto CPU, larga duraciÃ³n, moderada red)
cryptominer = np.column_stack([
    np.random.normal(0.7, 0.15, 30),   # uso_crypto (alto, para mining)
    np.random.normal(3, 1, 30),        # archivos_modificados (pocos)
    np.random.normal(86400, 10000, 30),# tiempo_ejecucion (muy largo)
    np.random.normal(0.3, 0.1, 30),    # trafico_red (pool connection)
    np.random.normal(0.85, 0.1, 30),   # persistencia
])

# Combinar
X = np.vstack([ransomware, spyware, botnet, cryptominer])
familias_reales = (['Ransomware']*40 + ['Spyware']*35 +
                   ['Botnet']*45 + ['Cryptominer']*30)

features = ['uso_crypto', 'archivos_mod', 'tiempo_ejec', 'trafico_red', 'persistencia']

print(f"Total muestras de malware: {len(X)}")
print(f"Features: {features}")

# Escalar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Crear dendrograma
print("\nCreando dendrograma...")
Z = linkage(X_scaled, method='ward')

plt.figure(figsize=(15, 8))
dendrogram(Z, truncate_mode='level', p=15,
           leaf_rotation=90, leaf_font_size=8)
plt.xlabel('Muestras de Malware')
plt.ylabel('Distancia (Ward)')
plt.title('Dendrograma de Familias de Malware')
plt.axhline(y=10, color='r', linestyle='--', label='Corte sugerido')
plt.legend()
plt.tight_layout()
plt.show()

# Analizar diferentes nÃºmeros de clusters
print("\nAnalizando diferentes cortes...")
for k in range(2, 7):
    labels = fcluster(Z, k, criterion='maxclust')
    score = silhouette_score(X_scaled, labels)
    print(f"  K={k}: Silhouette={score:.3f}")

# Clustering final
n_clusters = 4  # Sabemos que hay 4 familias
labels = fcluster(Z, n_clusters, criterion='maxclust')

# AnÃ¡lisis de resultados
print("\n" + "=" * 70)
print("ANÃLISIS DE FAMILIAS DE MALWARE DETECTADAS")
print("=" * 70)

df = pd.DataFrame(X, columns=features)
df['cluster'] = labels
df['familia_real'] = familias_reales

for cluster in sorted(df['cluster'].unique()):
    mask = df['cluster'] == cluster
    n = mask.sum()

    print(f"\n{'='*50}")
    print(f"CLUSTER {cluster} ({n} muestras)")
    print(f"{'='*50}")

    # CaracterÃ­sticas promedio
    print("\nCaracterÃ­sticas promedio:")
    for feat in features:
        val = df[mask][feat].mean()
        std = df[mask][feat].std()
        print(f"  {feat:15}: {val:.2f} (Â±{std:.2f})")

    # ComposiciÃ³n real
    print("\nFamilias reales en este cluster:")
    for familia, count in df[mask]['familia_real'].value_counts().items():
        pct = count / n * 100
        print(f"  {familia}: {count} ({pct:.1f}%)")

    # InterpretaciÃ³n automÃ¡tica
    avg_crypto = df[mask]['uso_crypto'].mean()
    avg_tiempo = df[mask]['tiempo_ejec'].mean()
    avg_red = df[mask]['trafico_red'].mean()
    avg_archivos = df[mask]['archivos_mod'].mean()

    print("\nğŸ“‹ InterpretaciÃ³n:")
    if avg_crypto > 0.7 and avg_tiempo < 100:
        print("  â†’ Comportamiento tÃ­pico de RANSOMWARE")
        print("    (alto cifrado, ejecuciÃ³n rÃ¡pida)")
    elif avg_red > 0.7 and avg_tiempo > 5000:
        print("  â†’ Comportamiento tÃ­pico de BOTNET")
        print("    (mucho trÃ¡fico de red, larga duraciÃ³n)")
    elif avg_tiempo > 50000:
        print("  â†’ Comportamiento tÃ­pico de CRYPTOMINER")
        print("    (ejecuciÃ³n muy prolongada)")
    elif avg_tiempo > 1000 and avg_red > 0.3 and avg_red < 0.7:
        print("  â†’ Comportamiento tÃ­pico de SPYWARE")
        print("    (ejecuciÃ³n larga, monitoreo)")

# Matriz de confusiÃ³n
print("\n" + "=" * 70)
print("MATRIZ: CLUSTER vs FAMILIA REAL")
print("=" * 70)
confusion = pd.crosstab(df['cluster'], df['familia_real'])
print(confusion)

# VisualizaciÃ³n con PCA
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(12, 8))

# Plot por cluster detectado
for cluster in sorted(set(labels)):
    mask = labels == cluster
    plt.scatter(X_pca[mask, 0], X_pca[mask, 1],
               alpha=0.7, s=60, label=f'Cluster {cluster}')

plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)')
plt.title('Clustering JerÃ¡rquico de Familias de Malware')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

## 7. Ventajas y Desventajas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VENTAJAS DEL CLUSTERING JERÃRQUICO                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ“ NO requiere especificar K de antemano                       â”‚
â”‚  âœ“ Dendrograma permite explorar diferentes K                   â”‚
â”‚  âœ“ VisualizaciÃ³n intuitiva de relaciones                       â”‚
â”‚  âœ“ DeterminÃ­stico (mismo resultado siempre)                    â”‚
â”‚  âœ“ Flexible con diferentes linkages                            â”‚
â”‚  âœ“ Puede usar cualquier mÃ©trica de distancia                   â”‚
â”‚  âœ“ Revela estructura jerÃ¡rquica de los datos                   â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DESVENTAJAS DEL CLUSTERING JERÃRQUICO                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ— Lento para datasets grandes O(nÂ²) a O(nÂ³)                   â”‚
â”‚  âœ— Requiere O(nÂ²) memoria para matriz de distancias            â”‚
â”‚  âœ— Una vez hecha una uniÃ³n, no se puede deshacer               â”‚
â”‚  âœ— Sensible a outliers (especialmente single linkage)          â”‚
â”‚  âœ— No asigna nuevos puntos directamente                        â”‚
â”‚  âœ— Puede ser difÃ­cil elegir el corte correcto                  â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 8. CuÃ¡ndo Usar Clustering JerÃ¡rquico

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CASOS DE USO IDEALES                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ“ No sabes cuÃ¡ntos clusters hay                               â”‚
â”‚  âœ“ Quieres explorar la estructura de los datos                 â”‚
â”‚  âœ“ Datos tienen estructura jerÃ¡rquica natural                  â”‚
â”‚  âœ“ Dataset pequeÃ±o/mediano (< 10,000 muestras)                 â”‚
â”‚  âœ“ TaxonomÃ­as (clasificaciÃ³n de especies, malware, etc.)       â”‚
â”‚  âœ“ AnÃ¡lisis exploratorio                                       â”‚
â”‚                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EVITAR CUANDO                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ— Dataset muy grande (> 10,000)                               â”‚
â”‚  âœ— Necesitas asignar nuevos puntos frecuentemente              â”‚
â”‚  âœ— Memoria limitada                                            â”‚
â”‚  âœ— Clusters esfÃ©ricos y conoces K (usar K-Means)               â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 9. Resumen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLUSTERING JERÃRQUICO - RESUMEN                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  CONCEPTO:                                                     â”‚
â”‚    Crear jerarquÃ­a de clusters (Ã¡rbol/dendrograma)             â”‚
â”‚    No requiere K de antemano                                   â”‚
â”‚                                                                â”‚
â”‚  TIPOS:                                                        â”‚
â”‚    â€¢ Aglomerativo (bottom-up): mÃ¡s comÃºn                       â”‚
â”‚    â€¢ Divisivo (top-down): menos usado                          â”‚
â”‚                                                                â”‚
â”‚  LINKAGES:                                                     â”‚
â”‚    â€¢ Single: mÃ­nima distancia (clusters alargados)             â”‚
â”‚    â€¢ Complete: mÃ¡xima distancia (clusters compactos)           â”‚
â”‚    â€¢ Average: promedio de distancias                           â”‚
â”‚    â€¢ Ward: minimiza varianza (â˜… mÃ¡s recomendado)               â”‚
â”‚                                                                â”‚
â”‚  DENDROGRAMA:                                                  â”‚
â”‚    â€¢ Eje Y = distancia de uniÃ³n                                â”‚
â”‚    â€¢ Cortar horizontalmente define K                           â”‚
â”‚                                                                â”‚
â”‚  EN CIBERSEGURIDAD:                                            â”‚
â”‚    â€¢ AgrupaciÃ³n de malware por familia                         â”‚
â”‚    â€¢ TaxonomÃ­as de amenazas                                    â”‚
â”‚    â€¢ AnÃ¡lisis de similitud entre ataques                       â”‚
â”‚    â€¢ CorrelaciÃ³n de IOCs                                       â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Siguiente:** Gaussian Mixture Models
